{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Manual-code categorization of surface-forms and errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the corrections made by the LLM in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import difflib\n",
    "punctuation += \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(c): return unicodedata.normalize('NFKD', c).encode('ASCII', 'ignore').decode()\n",
    "\n",
    "def useful_chars(string): return re.sub(r'[^a-zA-ZÀ-ÿ]', '', string)\n",
    "def isuseful_chars(string): return re.compile(r'^[a-zA-ZáéíóúÁÉÍÓÚüÜñÑ\\s,.!?¿¡]*$').match(string)\n",
    "\n",
    "def count_accent_changes(str1, str2):\n",
    "    if len(str1) != len(str2):\n",
    "        return -1\n",
    "\n",
    "    changes = 0\n",
    "    for char1, char2 in zip(str1, str2):\n",
    "        if char1 != char2 and normalize(char1) == normalize(char2):\n",
    "            changes += 1\n",
    "    return changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Go back to this point to reset all the applied categorizations and start over the debugging process, when required.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIONS_FILE = \"./correctionsLatam.json\"\n",
    "SURFACE_FORMS_FILE = \"../data/surfaceForms.json\"\n",
    "SURFACE_FORMS_FILE_NONACC = \"../data/surfaceFormsNonAccents.json\"\n",
    "ORTHOGRAPHIC_ERRORS_FILE = \"../data/orthographicErrors.json\"\n",
    "COLOR_PRINTING = False # for large corpus, set it to False\n",
    "current_step = 0\n",
    "\n",
    "df = pd.read_parquet(\"../data/pre-corrected-latam-xix.parquet\")\n",
    "\n",
    "with open(CORRECTIONS_FILE, 'r') as infile:\n",
    "    fixes = json.load(infile)\n",
    "\n",
    "if not os.path.exists(SURFACE_FORMS_FILE):\n",
    "    with open(SURFACE_FORMS_FILE, 'w') as outfile:\n",
    "        json.dump({}, outfile)\n",
    "surface_forms = dict()\n",
    "\n",
    "if not os.path.exists(SURFACE_FORMS_FILE_NONACC):\n",
    "    with open(SURFACE_FORMS_FILE_NONACC, 'w') as outfile:\n",
    "        json.dump({}, outfile)\n",
    "surface_forms_nacc = dict()\n",
    "\n",
    "if not os.path.exists(ORTHOGRAPHIC_ERRORS_FILE):\n",
    "    with open(ORTHOGRAPHIC_ERRORS_FILE, 'w') as outfile:\n",
    "        json.dump([], outfile)\n",
    "orthographic_errors = dict() # will be changed to list before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114411 fixes to check\n",
      "0 surface forms found\n",
      "0 orthographic errors found\n"
     ]
    }
   ],
   "source": [
    "def add_to_surface(wrong, good, freq):\n",
    "    sf_t, real_t = wrong.lower(), good.lower()\n",
    "    sf_ws, real_ws = re.findall(r'\\w+', sf_t), re.findall(r'\\w+', real_t)\n",
    "\n",
    "    if len(sf_ws) == len(real_ws):\n",
    "        for sf,real in zip(sf_ws, real_ws):\n",
    "            if sf != real:\n",
    "                numaccentchanges = count_accent_changes(real, sf)\n",
    "                surface_forms[real] = surface_forms.get(real, dict())\n",
    "                surface_forms[real][sf] = surface_forms[real].get(sf, 0) + freq\n",
    "                if numaccentchanges < 1:\n",
    "                    surface_forms_nacc[real] = surface_forms_nacc.get(real, dict())\n",
    "                    surface_forms_nacc[real][sf] = surface_forms_nacc[real].get(sf, 0) + freq\n",
    "\n",
    "    else:\n",
    "        if sf_t != real_t:\n",
    "            numaccentchanges = count_accent_changes(real_t, sf_t)\n",
    "            surface_forms[real_t] = surface_forms.get(real_t, dict())\n",
    "            surface_forms[real_t][sf_t] = surface_forms[real_t].get(sf_t, 0) + freq\n",
    "            if numaccentchanges < 1:\n",
    "                surface_forms_nacc[real_t] = surface_forms_nacc.get(real_t, dict())\n",
    "                surface_forms_nacc[real_t][sf_t] = surface_forms_nacc[real_t].get(sf_t, 0) + freq\n",
    "\n",
    "def add_to_errors(fix):\n",
    "    for idx,widx1,widx2,ctx in fix['usages']:\n",
    "        orthographic_errors[(idx,widx1,widx2)] = {\n",
    "            \"prv\": fix['change'][0],\n",
    "            \"mod\": fix['change'][1],\n",
    "            \"ctx\": ctx\n",
    "        }\n",
    "\n",
    "def print_fix(wrong, good, freq, category):\n",
    "    if COLOR_PRINTING:\n",
    "        if category == \"SFRM\": \n",
    "            category = f\"[\\033[93m{category}\"\n",
    "        elif category == \"ERRR\":\n",
    "            category = f\"[\\033[95m{category}\"\n",
    "        else:\n",
    "            category = f\"[\\033[90m{category}\"\n",
    "        print(f\"{category}\\033[0m] (\\033[92m{freq}\\033[0m) \\033[91m{wrong}\\033[0m - \\033[94m{good}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"[{category}] ({freq}) {wrong} - {good}\")\n",
    "\n",
    "def execute_prev_steps(step):\n",
    "    if step <= current_step + 1:\n",
    "        return\n",
    "    elif step - 2 > current_step:\n",
    "        raise Exception(f\"Execute step {step-2} first\")\n",
    "    else:\n",
    "        if step >= 2:\n",
    "            i = step-1\n",
    "            print(f\"Executing step {i}...\")\n",
    "            globals()[f\"step{i}\"](False)\n",
    "            status()\n",
    "\n",
    "status = lambda: print(f\"{len(fixes)} fixes to check\\n{len(surface_forms)} surface forms found\\n{len(orthographic_errors)} orthographic errors found\")\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La publicacion del Oso se harà dos veces cada semana, y constará de un pliego en cuarto ; ofreciendo à mas sus redactores, dar los gravados oportunos, siempre que lo exija el asunto de que trate. Redactado por un Num. 8. TEMA del Periodico. POLITICA MILITAR. OCTAVA SESION. Abierta la sesion á las dore y un minuto de la noche , 25 de Febrero de 1845 , con asistencia de todos los Señores Representantes, se leyó y aprobó la acta de la Asamblea anterior , ménos en lo tocante à la torre del Convento de Santo Domingo, punto que quedó para ventilarse en mejor ocasion. Enseguida se dió cuenta de una nota del Ejecutivo , referente à que urjía la necesidad de organizar un Ejército ; pues decia el Excmo. Decano: - \"Un poder sin bayonetas vale tanto como un cero puesto á la izquierda.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually-written steps for categorization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "\n",
    "- Each correction made by the LLM may be categorized as:\n",
    "  * **surface form**: with the method `add_to_surface`\n",
    "  * **orthographic error**: with the method `add_to_errors`\n",
    "  * **none**: just `pass` (skip) the correction\n",
    "\n",
    "- Each step has a `JUST_PRINT` variable; if it's True, the changes won't affect the variables. For debugging a particular step:\n",
    "  * First, **ALWAYS run all the previous steps with the `JUST_PRINT` variable set to False**\n",
    "  * Then, set the `JUST_PRINT` variable of the step you want to debug to True and run the step\n",
    "  * If you run the next step without running the previous one (with `JUST_PRINT`=False), it'll run the previous automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_CHANGES = [\n",
    "    ('á','a'), ('a','á'),\n",
    "    ('é','e'), ('e','é'),\n",
    "    ('í','i'), ('i','í'),\n",
    "    ('ó','o'), ('o','ó'),\n",
    "    ('ú','u'), ('u','ú'),\n",
    "    ('i','y'), ('y','i'),\n",
    "    ('j','g'), ('g','j'),\n",
    "    ('v','b'), ('b','v'),\n",
    "    ('s','x'), ('x','s'),\n",
    "    ('j','x'), ('x','j'),\n",
    "    ('c','s'), ('s','c'),\n",
    "    ('s','z'), ('z','s'),\n",
    "    ('z','c'),\n",
    "    ('q','c'), # quatro\n",
    "    ('n','ñ'), # senor\n",
    "    ('ni','ñ'), # senior\n",
    "    ('k','qu'), # nikel\n",
    "    ('k','c'), # kiosko\n",
    "    ('ou','u'), # boulevares\n",
    "    ('s','bs'), ('bs','s'), # suscriciones, obscuro\n",
    "    ('c','pc'), # suscriciones\n",
    "    ('s','ns'), # trasportar\n",
    "    ('t','pt'), # Setiembre\n",
    "    ('rt','r'), # libertar\n",
    "    ('rr','r'), ('r', 'rr'), # vireinato\n",
    "]\n",
    "# other common form is '...lo' -> 'lo ...' (e.g. cambiólo -> lo cambió)\n",
    "\n",
    "ERR_CHANGES = [\n",
    "    ('6','ó'), ('6','o'), ('1','y'), ('0','o'), ('4','a')\n",
    "]\n",
    "\n",
    "SF_EXCEPTIONS = [\n",
    "    \"presidenta\", \"sr.\", \"q'\", \"ud.\", \"d.\", \"usté\", \"apuntaciones\", \"comprofesores\",\n",
    "    \"diez y seis\", \"bien que\", \"de el\", \"costarrica\", \"hispano-america\", \"eleccionario\",\n",
    "    \"medio dia\", \"fortísimos\"\n",
    "]\n",
    "\n",
    "ERR_EXCEPTIONS = [\n",
    "    \n",
    "]\n",
    "\n",
    "SKIP = [\n",
    "    \"sugestiones\", \"suerte\", \"camonel\", \"mas\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['b', 'p'], [], [], [('s', 'bs'), ('c', 'pc')], [])\n",
      "([], ['b'], [], [], [('bs', 's')])\n",
      "([], [], [('e', 'é')], [], [])\n"
     ]
    }
   ],
   "source": [
    "def diff(text1, text2):\n",
    "    sm = difflib.SequenceMatcher(None, text1, text2)\n",
    "    added = []\n",
    "    removed = []\n",
    "    modified = []\n",
    "    add_modified = []\n",
    "    rmv_modified = []\n",
    "    for opcode, a0, a1, b0, b1 in sm.get_opcodes():\n",
    "        sa = sm.a[a0:a1]\n",
    "        sb = sm.b[b0:b1]\n",
    "        match opcode:\n",
    "            case 'insert': \n",
    "                added.append(sb)\n",
    "                if sm.a[a0:a1+1] != '': add_modified.append((sm.a[a0:a1+1], sm.b[b0:b1+1]))\n",
    "            case 'delete': \n",
    "                removed.append(sa)\n",
    "                if sm.b[b0:b1+1] != '': rmv_modified.append((sm.a[a0:a1+1], sm.b[b0:b1+1]))\n",
    "            case 'replace': modified.append((sa, sb))\n",
    "            case _: pass\n",
    "    return added, removed, modified, add_modified, rmv_modified\n",
    "\n",
    "print(diff('suscriciones', 'subscripciones'))   # added example\n",
    "print(diff('obscuro', 'oscuro'))                # removed example\n",
    "print(diff('ejercito', 'ejército'))             # modified example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['n'], [], [], [('s', 'ns')], [])\n",
      "(['nde'], [], [], [], [])\n",
      "([], ['_'], [], [], [])\n",
      "([], ['de'], [], [], [])\n",
      "(['c'], [], [('u', 'ú')], [], [])\n",
      "([], [], [('k', 'qu')], [], [])\n"
     ]
    }
   ],
   "source": [
    "print(diff('trascurso', 'transcurso'))\n",
    "print(diff('do', 'donde'))\n",
    "print(diff('y_', 'y'))\n",
    "print(diff('yde', 'y'))\n",
    "print(diff('republi', \"repúblic\"))\n",
    "print(diff('nikel', \"niquel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similarity(text1, text2):\n",
    "    return difflib.SequenceMatcher(None, text1, text2).ratio()\n",
    "\n",
    "similarity('apropósito', 'apropiado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUST_PRINT = False\n",
    "def sfrm(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"SFRM\")\n",
    "    else: add_to_surface(*fix['change'], fix['freq'])\n",
    "\n",
    "def errr(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"ERRR\")\n",
    "    else: add_to_errors(fix)\n",
    "\n",
    "def none(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"NONE\")\n",
    "    #else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114411 fixes to check\n",
      "11397 surface forms found\n",
      "12060 orthographic errors found\n"
     ]
    }
   ],
   "source": [
    "JUST_PRINT = False\n",
    "\n",
    "def step1():\n",
    "    global curent_step, JUST_PRINT\n",
    "    execute_prev_steps(1)\n",
    "    if JUST_PRINT == False: curent_step=1\n",
    "\n",
    "    idx_remove = []\n",
    "    for i,fix in enumerate(fixes):\n",
    "        if fix['change'][0].lower() in SF_EXCEPTIONS: sfrm(fix)\n",
    "        elif fix['change'][0].lower() in ERR_EXCEPTIONS: errr(fix)\n",
    "        elif fix['change'][0].lower() in SKIP: none(fix)\n",
    "        else:\n",
    "            added, removed, modified, add_modified, rmv_modified = diff(fix['change'][0].lower(), fix['change'][1].lower())\n",
    "            added_nz, removed_nz, modified_nz, add_modified_nz, rmv_modified_nz = diff(normalize(fix['change'][0].lower()), normalize(fix['change'][1].lower()))\n",
    "            if len(re.findall(r'\\w+', fix['change'][0])) == len(re.findall(r'\\w+', fix['change'][1])):\n",
    "                allchanges = modified+add_modified+rmv_modified\n",
    "                allchanges_nz = modified_nz+add_modified_nz+rmv_modified_nz\n",
    "                if (all([i in SF_CHANGES for i in allchanges]) and len(allchanges) != 0 and len(added) == len(add_modified) and len(removed) == len(rmv_modified)):\n",
    "                    sfrm(fix)\n",
    "                elif (all([i in SF_CHANGES for i in allchanges_nz]) and len(allchanges_nz) != 0 and len(added_nz) == len(add_modified_nz) and len(removed_nz) == len(rmv_modified_nz)):\n",
    "                    if isuseful_chars(fix['change'][0]): sfrm(fix)\n",
    "                    else: none(fix)\n",
    "                elif (all([i in ERR_CHANGES for i in allchanges]) and len(allchanges) != 0 and len(added) == len(add_modified) and len(removed) == len(rmv_modified)) or (all([i in ERR_CHANGES for i in allchanges_nz]) and len(allchanges_nz) != 0 and len(added_nz) == len(add_modified_nz) and len(removed_nz) == len(rmv_modified_nz)): \n",
    "                    errr(fix)\n",
    "            else:\n",
    "                if (len(added_nz) == len(removed_nz) == 1)  and (added_nz[0] == removed_nz[0]+\" \"): \n",
    "                    #temp, JUST_PRINT = JUST_PRINT, True\n",
    "                    ch0 = fix['change'][0].split()[0]\n",
    "                    ch1 = ' '.join(fix['change'][1].split()[:2])\n",
    "                    if normalize(ch0[:-len(added_nz[0])+1].lower()) == normalize(fix['change'][1].split()[1].lower()): # vióse, cambiólo, ...\n",
    "                        fix['change'][0] = ch0\n",
    "                        fix['change'][1] = ch1\n",
    "                        sfrm(fix)\n",
    "                    else: none(fix)\n",
    "                    #JUST_PRINT = temp\n",
    "                elif (fix['freq'] >= 5) or (similarity(*fix['change']) > 0.75): errr(fix)\n",
    "                else: none(fix)\n",
    "        idx_remove.append(i)\n",
    "\n",
    "    #if JUST_PRINT: print(len(idx_remove))\n",
    "    #else: \n",
    "    #    for i in reversed(idx_remove): fixes.pop(i)\n",
    "\n",
    "step1()\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_forms = {k: v for k,v in sorted(surface_forms.items(), key=lambda x: sum(x[1].values()), reverse=True)}\n",
    "surface_forms_nacc = {k: v for k,v in sorted(surface_forms_nacc.items(), key=lambda x: sum(x[1].values()), reverse=True)}\n",
    "\n",
    "with open(SURFACE_FORMS_FILE_NONACC, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(surface_forms_nacc, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(SURFACE_FORMS_FILE, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(surface_forms, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prv': 'à mas',\n",
       "  'mod': 'además',\n",
       "  'ctx': 'pliego en cuarto ; ofreciendo à mas sus redactores , dar los',\n",
       "  'idx1': 101,\n",
       "  'idx2': 106}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthographic_errors = dict(sorted(orthographic_errors.items(), key=lambda item: (item[0][0], item[0][1])))\n",
    "\n",
    "errors = [[] for _ in range(len(df))]\n",
    "for k,v in orthographic_errors.items():\n",
    "    v['idx1'] = k[1]\n",
    "    v['idx2'] = k[2]\n",
    "    errors[k[0]].append(v)\n",
    "\n",
    "with open(ORTHOGRAPHIC_ERRORS_FILE, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(errors, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "errors[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
