{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Manual-code categorization of surface-forms and errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the corrections made by the LLM in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import difflib\n",
    "punctuation += \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(c): return unicodedata.normalize('NFKD', c).encode('ASCII', 'ignore').decode()\n",
    "\n",
    "def useful_chars(string): return re.sub(r'[^a-zA-ZÀ-ÿ]', '', string)\n",
    "def isuseful_chars(string): return re.compile(r'^[a-zA-ZáéíóúÁÉÍÓÚüÜñÑ\\s,.!?¿¡]*$').match(string)\n",
    "\n",
    "def count_accent_changes(str1, str2):\n",
    "    if len(str1) != len(str2):\n",
    "        return -1\n",
    "\n",
    "    changes = 0\n",
    "    for char1, char2 in zip(str1, str2):\n",
    "        if char1 != char2 and normalize(char1) == normalize(char2):\n",
    "            changes += 1\n",
    "    return changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Go back to this point to reset all the applied categorizations and start over the debugging process, when required.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIONS_FILE = \"./correctionsLatam.json\"\n",
    "SURFACE_FORMS_FILE = \"../data/surfaceForms.json\"\n",
    "SURFACE_FORMS_FILE_NONACC = \"../data/surfaceFormsNonAccents.json\"\n",
    "ORTHOGRAPHIC_ERRORS_FILE = \"../data/orthographicErrors.json\"\n",
    "COLOR_PRINTING = False # for large corpus, set it to False\n",
    "current_step = 0\n",
    "\n",
    "df = pd.read_parquet(\"../data/pre-corrected-latam-xix.parquet\")\n",
    "\n",
    "with open(CORRECTIONS_FILE, 'r') as infile:\n",
    "    fixes = json.load(infile)\n",
    "\n",
    "if not os.path.exists(SURFACE_FORMS_FILE):\n",
    "    with open(SURFACE_FORMS_FILE, 'w') as outfile:\n",
    "        json.dump({}, outfile)\n",
    "surface_forms = dict()\n",
    "\n",
    "if not os.path.exists(SURFACE_FORMS_FILE_NONACC):\n",
    "    with open(SURFACE_FORMS_FILE_NONACC, 'w') as outfile:\n",
    "        json.dump({}, outfile)\n",
    "surface_forms_nacc = dict()\n",
    "\n",
    "if not os.path.exists(ORTHOGRAPHIC_ERRORS_FILE):\n",
    "    with open(ORTHOGRAPHIC_ERRORS_FILE, 'w') as outfile:\n",
    "        json.dump([], outfile)\n",
    "orthographic_errors = dict() # will be changed to list before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830951 fixes to check\n",
      "0 surface forms found\n",
      "0 orthographic errors found\n"
     ]
    }
   ],
   "source": [
    "def add_to_surface(wrong, good, freq):\n",
    "    sf_t, real_t = wrong.lower(), good.lower()\n",
    "    sf_ws, real_ws = re.findall(r'\\w+', sf_t), re.findall(r'\\w+', real_t)\n",
    "\n",
    "    if len(sf_ws) == len(real_ws):\n",
    "        for sf,real in zip(sf_ws, real_ws):\n",
    "            if sf != real:\n",
    "                numaccentchanges = count_accent_changes(real, sf)\n",
    "                surface_forms[real] = surface_forms.get(real, dict())\n",
    "                surface_forms[real][sf] = surface_forms[real].get(sf, 0) + freq\n",
    "                if numaccentchanges < 1:\n",
    "                    surface_forms_nacc[real] = surface_forms_nacc.get(real, dict())\n",
    "                    surface_forms_nacc[real][sf] = surface_forms_nacc[real].get(sf, 0) + freq\n",
    "\n",
    "    else:\n",
    "        if sf_t != real_t:\n",
    "            numaccentchanges = count_accent_changes(real_t, sf_t)\n",
    "            surface_forms[real_t] = surface_forms.get(real_t, dict())\n",
    "            surface_forms[real_t][sf_t] = surface_forms[real_t].get(sf_t, 0) + freq\n",
    "            if numaccentchanges < 1:\n",
    "                surface_forms_nacc[real_t] = surface_forms_nacc.get(real_t, dict())\n",
    "                surface_forms_nacc[real_t][sf_t] = surface_forms_nacc[real_t].get(sf_t, 0) + freq\n",
    "\n",
    "def add_to_errors(fix):\n",
    "    for idx,widx1,widx2,ctx in fix['usages']:\n",
    "        orthographic_errors[(idx,widx1,widx2)] = {\n",
    "            \"prv\": fix['change'][0],\n",
    "            \"mod\": fix['change'][1],\n",
    "            \"ctx\": ctx\n",
    "        }\n",
    "\n",
    "def print_fix(wrong, good, freq, category):\n",
    "    if COLOR_PRINTING:\n",
    "        if category == \"SFRM\": \n",
    "            category = f\"[\\033[93m{category}\"\n",
    "        elif category == \"ERRR\":\n",
    "            category = f\"[\\033[95m{category}\"\n",
    "        else:\n",
    "            category = f\"[\\033[90m{category}\"\n",
    "        print(f\"{category}\\033[0m] (\\033[92m{freq}\\033[0m) \\033[91m{wrong}\\033[0m - \\033[94m{good}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"[{category}] ({freq}) {wrong} - {good}\")\n",
    "\n",
    "def execute_prev_steps(step):\n",
    "    if step <= current_step + 1:\n",
    "        return\n",
    "    elif step - 2 > current_step:\n",
    "        raise Exception(f\"Execute step {step-2} first\")\n",
    "    else:\n",
    "        if step >= 2:\n",
    "            i = step-1\n",
    "            print(f\"Executing step {i}...\")\n",
    "            globals()[f\"step{i}\"](False)\n",
    "            status()\n",
    "\n",
    "status = lambda: print(f\"{len(fixes)} fixes to check\\n{len(surface_forms)} surface forms found\\n{len(orthographic_errors)} orthographic errors found\")\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cualquier cosa, pues solo se hizo circular en hoja suelta: pero lo haremos conocer próximamente, AREQUIPA MARZO 5 DB 1884. Pues tenemos el propósito de no omitir : esfuerzo hasta conseguirla. Mientras tanto, como reminiscencias que de ella se conservan en la memoria, insertamos uno de sus fragmentos, que poco mas ó menos dice a \"Casas sin techo, Rio sin agua, Arboles sin hojas, Muchacho malcriado ... Todo esto era el Perú a la muerte del General Castilla.\" Si hay alguna alteracion en esta parte, el autor por interes propio debe exhibir la Oda para rectificarla, previniendose que aun cuando parezca exagerado, este fragmento es de los menos malos. Y a proposito. ¿ Que daño pudo haberle hecho a este pedante el ilustre General Castilia, que con tanto desden miraba a los pequeños, para que intentase escarnecer y poner en rídiculo su respetada memoria? Nos esplicamos el motivo del encono que abriga el Redactor de \"El Peru\" para el país de su nacimiento, pero ... la saña que revela no solo la hace estensiva a todo el Perú, sino que la lleva hasta Francia, y escoje á una de sus mas esclarecidas inteligencias, para presentarla con todas las sombras de la monstruosidad, traduciendo a Victor-Hugo, a la manera de aquel mal pintor que para vengarse de Nada habria de un enemigo suyo ... lo retrató. estraño en que si Valdes tuviera motivo de odio para Italia ó Alemania, por ejemplo, hicese variaciones sobre las mejores armonias de Rosini ó de Mozart. Mas, dejando à un lado esta digresion, nos preguntamos: ¿ que objeto se propuso el Hacedor Supremo al crear á este ser incalificable? ¡Inescrutables designios de la Providencia! Para formar el contraste ha sido necesario colocar á no al lado de la paloma, Is víbora; de las tinieblas, la luz; de la virtud, la perversidad; y del buen nombre de Arequipa, Valdes. Pero el lector preguntará que objeto tiene esta publicacion .- El siguiente: que por grande que haya sido el desprecio con que se ha mirado las infolices producciones del redactor de \"El Perú\" cuando no se ha cebado en la honra de personas cuya vida no presenta mancha, ha llegado el caso de que su procacidad y calumniosas aseveraciones, desmentidas por élá cada paso, sean reprimidas debidamente, a fin de que fuera del lugar sea desvanecido el mal concepto que el Sr. Valdes procura se tenga de Arequipa; pues como dice el distinguido crítico español D . Juan M. Villergas: \" Hay otra clase mas, contraria a la civilizacion .... y es la de los malos escritores, la de los literatos que hacen detestables traducciones, intolerables plagios, disparates groseros; en una pala'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually-written steps for categorization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "\n",
    "- Each correction made by the LLM may be categorized as:\n",
    "  * **surface form**: with the method `add_to_surface`\n",
    "  * **orthographic error**: with the method `add_to_errors`\n",
    "  * **none**: just `pass` (skip) the correction\n",
    "\n",
    "- Each step has a `JUST_PRINT` variable; if it's True, the changes won't affect the variables. For debugging a particular step:\n",
    "  * First, **ALWAYS run all the previous steps with the `JUST_PRINT` variable set to False**\n",
    "  * Then, set the `JUST_PRINT` variable of the step you want to debug to True and run the step\n",
    "  * If you run the next step without running the previous one (with `JUST_PRINT`=False), it'll run the previous automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_CHANGES = [\n",
    "    ('á','a'), ('a','á'),\n",
    "    ('é','e'), ('e','é'),\n",
    "    ('í','i'), ('i','í'),\n",
    "    ('ó','o'), ('o','ó'),\n",
    "    ('ú','u'), ('u','ú'),\n",
    "    ('i','y'), ('y','i'),\n",
    "    ('j','g'), ('g','j'),\n",
    "    ('v','b'), ('b','v'),\n",
    "    ('s','x'), ('x','s'),\n",
    "    ('j','x'), ('x','j'),\n",
    "    ('c','s'), ('s','c'),\n",
    "    ('s','z'), ('z','s'),\n",
    "    ('z','c'),\n",
    "    ('q','c'), # quatro\n",
    "    ('n','ñ'), # senor\n",
    "    ('ni','ñ'), # senior\n",
    "    ('k','qu'), # nikel\n",
    "    ('k','c'), # kiosko\n",
    "    ('ou','u'), # boulevares\n",
    "    ('s','bs'), ('bs','s'), # suscriciones, obscuro\n",
    "    ('c','pc'), # suscriciones\n",
    "    ('s','ns'), # trasportar\n",
    "    ('t','pt'), # Setiembre\n",
    "    ('rt','r'), # libertar\n",
    "    ('rr','r'), ('r', 'rr'), # vireinato\n",
    "]\n",
    "# other common form is '...lo' -> 'lo ...' (e.g. cambiólo -> lo cambió)\n",
    "\n",
    "ERR_CHANGES = [\n",
    "    ('6','ó'), ('6','o'), ('1','y'), ('0','o'), ('4','a')\n",
    "]\n",
    "\n",
    "SF_EXCEPTIONS = [\n",
    "    \"presidenta\", \"sr.\", \"q'\", \"ud.\", \"d.\", \"usté\", \"apuntaciones\", \"comprofesores\",\n",
    "    \"diez y seis\", \"bien que\", \"de el\", \"costarrica\", \"hispano-america\", \"eleccionario\",\n",
    "    \"medio dia\", \"fortísimos\"\n",
    "]\n",
    "\n",
    "ERR_EXCEPTIONS = [\n",
    "    \n",
    "]\n",
    "\n",
    "SKIP = [\n",
    "    \"sugestiones\", \"suerte\", \"camonel\", \"mas\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['b', 'p'], [], [], [('s', 'bs'), ('c', 'pc')], [])\n",
      "([], ['b'], [], [], [('bs', 's')])\n",
      "([], [], [('e', 'é')], [], [])\n"
     ]
    }
   ],
   "source": [
    "def diff(text1, text2):\n",
    "    sm = difflib.SequenceMatcher(None, text1, text2)\n",
    "    added = []\n",
    "    removed = []\n",
    "    modified = []\n",
    "    add_modified = []\n",
    "    rmv_modified = []\n",
    "    for opcode, a0, a1, b0, b1 in sm.get_opcodes():\n",
    "        sa = sm.a[a0:a1]\n",
    "        sb = sm.b[b0:b1]\n",
    "        match opcode:\n",
    "            case 'insert': \n",
    "                added.append(sb)\n",
    "                if sm.a[a0:a1+1] != '': add_modified.append((sm.a[a0:a1+1], sm.b[b0:b1+1]))\n",
    "            case 'delete': \n",
    "                removed.append(sa)\n",
    "                if sm.b[b0:b1+1] != '': rmv_modified.append((sm.a[a0:a1+1], sm.b[b0:b1+1]))\n",
    "            case 'replace': modified.append((sa, sb))\n",
    "            case _: pass\n",
    "    return added, removed, modified, add_modified, rmv_modified\n",
    "\n",
    "print(diff('suscriciones', 'subscripciones'))   # added example\n",
    "print(diff('obscuro', 'oscuro'))                # removed example\n",
    "print(diff('ejercito', 'ejército'))             # modified example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['n'], [], [], [('s', 'ns')], [])\n",
      "(['nde'], [], [], [], [])\n",
      "([], ['_'], [], [], [])\n",
      "([], ['de'], [], [], [])\n",
      "(['c'], [], [('u', 'ú')], [], [])\n",
      "([], [], [('k', 'qu')], [], [])\n"
     ]
    }
   ],
   "source": [
    "print(diff('trascurso', 'transcurso'))\n",
    "print(diff('do', 'donde'))\n",
    "print(diff('y_', 'y'))\n",
    "print(diff('yde', 'y'))\n",
    "print(diff('republi', \"repúblic\"))\n",
    "print(diff('nikel', \"niquel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similarity(text1, text2):\n",
    "    return difflib.SequenceMatcher(None, text1, text2).ratio()\n",
    "\n",
    "similarity('apropósito', 'apropiado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUST_PRINT = False\n",
    "def sfrm(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"SFRM\")\n",
    "    else: add_to_surface(*fix['change'], fix['freq'])\n",
    "\n",
    "def errr(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"ERRR\")\n",
    "    else: add_to_errors(fix)\n",
    "\n",
    "def none(fix):\n",
    "    if JUST_PRINT: print_fix(*fix['change'], fix['freq'], \"NONE\")\n",
    "    #else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830951 fixes to check\n",
      "37475 surface forms found\n",
      "102689 orthographic errors found\n"
     ]
    }
   ],
   "source": [
    "JUST_PRINT = False\n",
    "\n",
    "def step1():\n",
    "    global curent_step, JUST_PRINT\n",
    "    execute_prev_steps(1)\n",
    "    if JUST_PRINT == False: curent_step=1\n",
    "\n",
    "    idx_remove = []\n",
    "    for i,fix in enumerate(fixes):\n",
    "        if fix['change'][0].lower() in SF_EXCEPTIONS: sfrm(fix)\n",
    "        elif fix['change'][0].lower() in ERR_EXCEPTIONS: errr(fix)\n",
    "        elif fix['change'][0].lower() in SKIP: none(fix)\n",
    "        else:\n",
    "            added, removed, modified, add_modified, rmv_modified = diff(fix['change'][0].lower(), fix['change'][1].lower())\n",
    "            added_nz, removed_nz, modified_nz, add_modified_nz, rmv_modified_nz = diff(normalize(fix['change'][0].lower()), normalize(fix['change'][1].lower()))\n",
    "            if len(re.findall(r'\\w+', fix['change'][0])) == len(re.findall(r'\\w+', fix['change'][1])):\n",
    "                allchanges = modified+add_modified+rmv_modified\n",
    "                allchanges_nz = modified_nz+add_modified_nz+rmv_modified_nz\n",
    "                if (all([i in SF_CHANGES for i in allchanges]) and len(allchanges) != 0 and len(added) == len(add_modified) and len(removed) == len(rmv_modified)):\n",
    "                    sfrm(fix)\n",
    "                elif (all([i in SF_CHANGES for i in allchanges_nz]) and len(allchanges_nz) != 0 and len(added_nz) == len(add_modified_nz) and len(removed_nz) == len(rmv_modified_nz)):\n",
    "                    if isuseful_chars(fix['change'][0]): sfrm(fix)\n",
    "                    else: none(fix)\n",
    "                elif (all([i in ERR_CHANGES for i in allchanges]) and len(allchanges) != 0 and len(added) == len(add_modified) and len(removed) == len(rmv_modified)) or (all([i in ERR_CHANGES for i in allchanges_nz]) and len(allchanges_nz) != 0 and len(added_nz) == len(add_modified_nz) and len(removed_nz) == len(rmv_modified_nz)): \n",
    "                    errr(fix)\n",
    "            else:\n",
    "                if (len(added_nz) == len(removed_nz) == 1)  and (added_nz[0] == removed_nz[0]+\" \"): \n",
    "                    #temp, JUST_PRINT = JUST_PRINT, True\n",
    "                    ch0 = fix['change'][0].split()[0]\n",
    "                    ch1 = ' '.join(fix['change'][1].split()[:2])\n",
    "                    if normalize(ch0[:-len(added_nz[0])+1].lower()) == normalize(fix['change'][1].split()[1].lower()): # vióse, cambiólo, ...\n",
    "                        fix['change'][0] = ch0\n",
    "                        fix['change'][1] = ch1\n",
    "                        sfrm(fix)\n",
    "                    else: none(fix)\n",
    "                    #JUST_PRINT = temp\n",
    "                elif (fix['freq'] >= 5) or (similarity(*fix['change']) > 0.75): errr(fix)\n",
    "                else: none(fix)\n",
    "        idx_remove.append(i)\n",
    "\n",
    "    #if JUST_PRINT: print(len(idx_remove))\n",
    "    #else: \n",
    "    #    for i in reversed(idx_remove): fixes.pop(i)\n",
    "\n",
    "step1()\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_forms = {k: v for k,v in sorted(surface_forms.items(), key=lambda x: sum(x[1].values()), reverse=True)}\n",
    "surface_forms_nacc = {k: v for k,v in sorted(surface_forms_nacc.items(), key=lambda x: sum(x[1].values()), reverse=True)}\n",
    "\n",
    "with open(SURFACE_FORMS_FILE_NONACC, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(surface_forms_nacc, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(SURFACE_FORMS_FILE, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(surface_forms, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthographic_errors = dict(sorted(orthographic_errors.items(), key=lambda item: (item[0][0], item[0][1])))\n",
    "\n",
    "errors = [[] for _ in range(len(df))]\n",
    "for k,v in orthographic_errors.items():\n",
    "    v['idx1'] = k[1]\n",
    "    v['idx2'] = k[2]\n",
    "    errors[k[0]].append(v)\n",
    "\n",
    "with open(ORTHOGRAPHIC_ERRORS_FILE, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(errors, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prv': 'oiga mosle á',\n",
       "  'mod': 'oigámosle a',\n",
       "  'ctx': 'exhibir la indicada muestra , oiga mosle á él en su prólogo que',\n",
       "  'idx1': 1420,\n",
       "  'idx2': 1432},\n",
       " {'prv': 'bellisímas traduccio. nes',\n",
       "  'mod': 'bellísimas traducciones',\n",
       "  'ctx': 'embargo están escritos . Las bellisímas traduccio . nes de Victor - Hugo por',\n",
       "  'idx1': 2371,\n",
       "  'idx2': 2396}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Se meten á escribir: y no veo yo lejano el dia en que cada pueblo sacrifique un centenar de estos feroces vípedos, de la misma manera que los antiguos sacrificaban bueyes. Y en efecto, esta clase de escritores, que quieren suplir con la audacia In falta de ciencia y de conciencia, son perjudiciales, no por el daño que hacen á los pueblos, a las institucciones ó á las doctrinas, que nada tienen que temer de tan débiles enemigos, sino por los errores, por las preocupaciones que siembran entre las gentes sencillas, que reciben como articulo de fé todo lo que ven en letra de moldey. Concluiremos repitiendo con uno de nuestros eminentes estadistas, que: «Ningun hombre de bien te tenga segura su conciencia, debe inquietarse por los denuestos de la prensa, pues las calumnias que vierte entre nosotros, algo de honroso dicen á favor de las víctimas de sus furores, siendo la mejor venganza contra esas vocinglerias, mostrarse cada dia mas indiferente a ellas y mas honrado». : 001 4 -201 050G eIP , Ecce homo! - \"b Para que los lectores de fuera conozcan &l redactor de \"El Perú\", vamos á dar una muestra de sus traducciones de Victor Hugo, que comenzó a dar a luz hace poco menos de dos años, habiendo repartido solo la primera entrega, no obstante de haber cobrado anticipadamente el precio de la obra; advirtiendo que ni por casualidad ha atinado a hacer un solo verso. .Pero antes de exhibir la indicada muestra, oiga mosle á él en su prólogo que comienza por \"Damos efusivos agradecimientos,\" ..... y sigue con\"Tengo el placer de publicar etc.\" Słuesta Nadie sino el era capaz de traducir al eminente poeta frances; pues dice asi: all mi \"La presente version no tiene mas merito que el de la exactitud y fidelidad. 7 1959/118089 \"He procurado conservar su originalidad, interpretando religiosamente su genio; dando a cada idea, a cada palabra, la fuerza y el significado que verdaderamente les corresponde. \"Victor-Hugo hasta hoy, no ha podido ser admirado mas que por las personas que saben el frances; las demás solo repetlan la voz que llena el globo, sin tener conciencia de ello, descansando en el fallo universal que le declara el poeta del siglo XIX. o . DE AQUÍ EN ADELANTE, todos podrán convencerse del poder y sublimidad de este genio en este fragmento de sus producciones». o Tales asertos rayan a en lo inverosímil, y sin embargo están escritos . Las bellisímas traduccio. nes de Victor-Hugo por Fernandez Neda, Llorente (Teodoro), la | Avellaneda, nuestro compatriota R. Palma y tantas otras notabilidades literarias, quedan magistralmente proscritas por el autor de la \"Oda 55\", no obstante de existir entre, aquellas y las de éste, la misma diferencia que , entre el hermoso faisan de la China y. ... un escuerzo. al ah \\'s La obra que nos ocupa comienza por \"La ciudad tomada\", y ha debido el traductor considerar esta parte entre las mejores que publica, cuando la ofrece como prospecto . Para presentar en relieve la monstruosidad de las traducciones, bastaría subrayar los disparates que ellas contienen; pero como estos guardan proporcion con el número de palabras, pudiendo sumarse varios desatinos por cada una, nos hemos limitado a señalar con letra cursiva solo los mas notables. He aquí algunos fragmentos: BUplay \"La flama por tu orden, oh! Rey, luce y devora; Tronando, de tu pueblo, sofoca los clamores; az Los techos rojeciendo como lobrega aurora, Parece que en sus restos gozara, en sus dolores. \"Madres se extremecieron! doncellas, palpitantes.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(errors):\n",
    "    text = df.loc[i, \"text\"]\n",
    "    chdif = 0\n",
    "    for v in e:\n",
    "        p = v['prv']\n",
    "        m = v['mod']\n",
    "        ctx = v['ctx']\n",
    "        idx1 = v['idx1'] - chdif\n",
    "        idx2 = v['idx2'] - chdif\n",
    "        assert p == text[idx1:idx2], f\"ERROR at {i}. Expected {p} but got {text[idx1:idx2]}\"\n",
    "        text = text[:idx1] + m + text[idx2:]\n",
    "        chdif += len(p) - len(m)\n",
    "    df.loc[i, \"text\"] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Se meten á escribir: y no veo yo lejano el dia en que cada pueblo sacrifique un centenar de estos feroces vípedos, de la misma manera que los antiguos sacrificaban bueyes. Y en efecto, esta clase de escritores, que quieren suplir con la audacia In falta de ciencia y de conciencia, son perjudiciales, no por el daño que hacen á los pueblos, a las institucciones ó á las doctrinas, que nada tienen que temer de tan débiles enemigos, sino por los errores, por las preocupaciones que siembran entre las gentes sencillas, que reciben como articulo de fé todo lo que ven en letra de moldey. Concluiremos repitiendo con uno de nuestros eminentes estadistas, que: «Ningun hombre de bien te tenga segura su conciencia, debe inquietarse por los denuestos de la prensa, pues las calumnias que vierte entre nosotros, algo de honroso dicen á favor de las víctimas de sus furores, siendo la mejor venganza contra esas vocinglerias, mostrarse cada dia mas indiferente a ellas y mas honrado». : 001 4 -201 050G eIP , Ecce homo! - \"b Para que los lectores de fuera conozcan &l redactor de \"El Perú\", vamos á dar una muestra de sus traducciones de Victor Hugo, que comenzó a dar a luz hace poco menos de dos años, habiendo repartido solo la primera entrega, no obstante de haber cobrado anticipadamente el precio de la obra; advirtiendo que ni por casualidad ha atinado a hacer un solo verso. .Pero antes de exhibir la indicada muestra, oigámosle a él en su prólogo que comienza por \"Damos efusivos agradecimientos,\" ..... y sigue con\"Tengo el placer de publicar etc.\" Słuesta Nadie sino el era capaz de traducir al eminente poeta frances; pues dice asi: all mi \"La presente version no tiene mas merito que el de la exactitud y fidelidad. 7 1959/118089 \"He procurado conservar su originalidad, interpretando religiosamente su genio; dando a cada idea, a cada palabra, la fuerza y el significado que verdaderamente les corresponde. \"Victor-Hugo hasta hoy, no ha podido ser admirado mas que por las personas que saben el frances; las demás solo repetlan la voz que llena el globo, sin tener conciencia de ello, descansando en el fallo universal que le declara el poeta del siglo XIX. o . DE AQUÍ EN ADELANTE, todos podrán convencerse del poder y sublimidad de este genio en este fragmento de sus producciones». o Tales asertos rayan a en lo inverosímil, y sin embargo están escritos . Las bellísimas traducciones de Victor-Hugo por Fernandez Neda, Llorente (Teodoro), la | Avellaneda, nuestro compatriota R. Palma y tantas otras notabilidades literarias, quedan magistralmente proscritas por el autor de la \"Oda 55\", no obstante de existir entre, aquellas y las de éste, la misma diferencia que , entre el hermoso faisan de la China y. ... un escuerzo. al ah \\'s La obra que nos ocupa comienza por \"La ciudad tomada\", y ha debido el traductor considerar esta parte entre las mejores que publica, cuando la ofrece como prospecto . Para presentar en relieve la monstruosidad de las traducciones, bastaría subrayar los disparates que ellas contienen; pero como estos guardan proporcion con el número de palabras, pudiendo sumarse varios desatinos por cada una, nos hemos limitado a señalar con letra cursiva solo los mas notables. He aquí algunos fragmentos: BUplay \"La flama por tu orden, oh! Rey, luce y devora; Tronando, de tu pueblo, sofoca los clamores; az Los techos rojeciendo como lobrega aurora, Parece que en sus restos gozara, en sus dolores. \"Madres se extremecieron! doncellas, palpitantes.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/corrected-latam-xix.tsv\", sep=\"\\t\", index=False)\n",
    "df.to_parquet('../data/corrected-latam-xix.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
